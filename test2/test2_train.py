# -*- coding: utf-8 -*-
"""test2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SxljgBtckp01S97YpbaSklDL4kIKyVe4
"""

import gradio as gr

import matplotlib.pyplot as plt # plt 用于显示图片
import matplotlib.image as mpimg # mpimg 用于读取图片
import numpy as np

from PIL import Image

# pytorch
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torch.nn.functional as F
from torch.optim.lr_scheduler import StepLR

num_classes = 10
# 超参数设置
num_epochs = 100
batch_size = 32
learning_rate = 0.005

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
# 数据预处理
transform0 = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
    ])
transform1 = transforms.Compose([
    #图形尺寸填充 填充至36x36
    transforms.Pad(4),
    #随机水平翻转
    transforms.RandomHorizontalFlip(),
    #随机裁剪 裁剪至32x32
    transforms.RandomCrop(32),
    transforms.ToTensor(),
    ])
transform2 = transforms.Compose([
    # 随机亮度调整
    transforms.ColorJitter(brightness=0.2),
    transforms.ToTensor(),
    ])

LOAD_CIFAR = True
DOWNLOAD_CIFAR = False
# 从data继承读取数据集的类
from torch.utils.data import Dataset, DataLoader

#训练集数据导入 用两种方法实现数据集扩充
train_data0 = torchvision.datasets.CIFAR10(root='/home/crq2/AI/dataset',train=True,
                     download=DOWNLOAD_CIFAR, transform=transform0)
train_data1 = torchvision.datasets.CIFAR10(root='/home/crq2/AI/dataset',train=True,
                     download=DOWNLOAD_CIFAR, transform=transform1)
train_data2 = torchvision.datasets.CIFAR10(root='/home/crq2/AI/dataset',train=True,
                     download=DOWNLOAD_CIFAR, transform=transform2)
concat_trainset = torch.utils.data.ConcatDataset([train_data0, train_data1, train_data2])

# 测试数据集
test_data = torchvision.datasets.CIFAR10(
    root='/home/crq2/AI/dataset',
    train=False,
    transform=transform0
)

# 训练数据加载器
train_loader = torch.utils.data.DataLoader(dataset=concat_trainset,
                                           batch_size=batch_size,
                                           shuffle=True)
# 测试数据加载器
test_loader = torch.utils.data.DataLoader(dataset=test_data,
                                          batch_size=batch_size,
                                          shuffle=False)

#定义残差块
class Residual(nn.Module):
    def __init__(self, input_channels, num_channels, use_1x1conv=False, strides=1,Resblock=False):  #需要判断是否需要1×1的卷积
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, num_channels,
                    kernel_size=3, padding=1, stride=strides)
        self.conv2 = nn.Conv2d(num_channels, num_channels,
                    kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2d(input_channels, num_channels,
                        kernel_size=1, stride=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm2d(num_channels)
        self.bn2 = nn.BatchNorm2d(num_channels)
        self.resblock = Resblock

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        if self.resblock:
            Y += X                                                 ###############################################可以去掉 不存在残差
        return F.relu(Y)


def resnet_block(input_channels, num_channels, num_residuals, first_block=False,res_block=False):
      blk = []
      for i in range(num_residuals):
          if i == 0 and not first_block:
              blk.append(Residual(input_channels, num_channels,use_1x1conv=True, strides=2,Resblock=res_block))
          else:
              blk.append(Residual(num_channels, num_channels,Resblock=res_block))
      return blk

# 生成Resnet
class ResNet(nn.Module):
    def __init__(self,resblock):
        super().__init__()
        self.b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),
                   nn.BatchNorm2d(64), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
        self.b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True,res_block=resblock))
        self.b3 = nn.Sequential(*resnet_block(64, 128, 2,res_block=resblock))
        self.b4 = nn.Sequential(*resnet_block(128, 256, 2,res_block=resblock))
        self.b5 = nn.Sequential(*resnet_block(256, 512, 2,res_block=resblock))
        self.linear = nn.Linear(512, 10)
        self.Aavgpool = nn.AdaptiveAvgPool2d((1,1))

    def forward(self, x):
        x = self.b1(x)
        x = self.b2(x)
        x = self.b3(x)
        x = self.b4(x)
        x = self.b5(x)
        x = self.Aavgpool(x)
        x = torch.flatten(x,1)
        x = self.linear(x)

        return x

# 实例化一个模型
model = ResNet(False)
model_resblock = ResNet(True)

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
optimizer2 = torch.optim.Adam(model_resblock.parameters(), lr=learning_rate)
# 自动调整学习率
scheduler = StepLR(optimizer, step_size=10, gamma=0.9)
scheduler2 = StepLR(optimizer2, step_size=10, gamma=0.9)

# 设置cuda-gpu
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

# 开始训练
model = model.cuda()
# 存储损失与精度
loss_history = []
accuracy_history = []

total_step = len(train_loader)
for epoch in range(num_epochs):
    running_loss = 0.0
    correct_train = 0
    total_train = 0
    for i, (images, labels) in enumerate(train_loader):

        images = images.cuda()
        labels = labels.cuda()
        # 前向传播
        outputs = model(images)
        loss = criterion(outputs, labels)

        # 反向传播和优化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        #累计损失
        running_loss += loss.item()
        # 计算准确率
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

        if (i+1) % 1000 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
    scheduler.step()
    #计算各epoch中的平均损失值和准确率
    avg_loss = running_loss / len(train_loader)
    accuracy = 100.0 * correct_train / total_train
    #存储平均损失值和准确率
    loss_history.append(avg_loss)
    accuracy_history.append(accuracy)
    #输出学习率
    print(f"Epoch [{epoch+1}/{num_epochs}], Learning Rate: {scheduler.get_lr()[0]}")

# 开始训练
model_resblock = model_resblock.cuda()
# 存储损失与精度
loss_history0=loss_history
accuracy_history0=accuracy_history
loss_history = []
accuracy_history = []

total_step = len(train_loader)
for epoch in range(num_epochs):
    running_loss = 0.0
    correct_train = 0
    total_train = 0
    for i, (images, labels) in enumerate(train_loader):

        images = images.cuda()
        labels = labels.cuda()
        # 前向传播
        outputs = model_resblock(images)
        loss = criterion(outputs, labels)

        # 反向传播和优化
        optimizer2.zero_grad()
        loss.backward()
        optimizer2.step()

        #累计损失
        running_loss += loss.item()
        # 计算准确率
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

        if (i+1) % 1000 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
    scheduler2.step()
    #计算各epoch中的平均损失值和准确率
    avg_loss = running_loss / len(train_loader)
    accuracy = 100.0 * correct_train / total_train
    #存储平均损失值和准确率
    loss_history.append(avg_loss)
    accuracy_history.append(accuracy)
    #输出学习率
    print(f"Epoch [{epoch+1}/{num_epochs}], Learning Rate: {scheduler2.get_lr()[0]}")

import pickle
file = open('lossres.pickle','wb')
pickle.dump(loss_history0,file)
file.close()
file = open('accres.pickle','wb')
pickle.dump(accuracy_history0,file)
file.close()
file = open('lossres_block.pickle','wb')
pickle.dump(loss_history,file)
file.close()
file = open('accres_block.pickle','wb')
pickle.dump(accuracy_history,file)
file.close()

#  保存模型
torch.save(model.state_dict(), 'modelres.ckpt')
torch.save(model_resblock.state_dict(), 'modelres_block.ckpt')

