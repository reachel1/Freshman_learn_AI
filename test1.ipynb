{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNz8R3qHrcamkN5SClUFps+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reachel1/Freshman_learn_AI/blob/main/test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHO9ZcicUtvv",
        "outputId": "3de324bc-40e1-4975-ac52-95f6feadce60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  5 09:21:03 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "# Importing drive method from colab for accessing google drive\n",
        "from google.colab import drive\n",
        "# Mounting drive\n",
        "# This will require authentication : Follow the steps as guided\n",
        "drive.mount('/Data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP7T3VlxWiCp",
        "outputId": "f6f9895b-01cc-421f-93d8-21826d95fd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /Data/'My Drive'/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBSdroL7fSA8",
        "outputId": "0b17b515-6b7a-46de-b7b0-3316bd31d33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10-python.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # plt 用于显示图片\n",
        "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
        "import numpy as np\n",
        "\n",
        "#resize功能\n",
        "from scipy import misc\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# 超参数设置\n",
        "num_epochs = 10\n",
        "num_classes = 10\n",
        "batch_size = 10\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "y9tms4NwcMFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# 数据增广方法\n",
        "transform = transforms.Compose([\n",
        "    # +4填充至36x36\n",
        "    transforms.Pad(4),\n",
        "    # 随机水平翻转\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # 随机裁剪至32x32\n",
        "    transforms.RandomCrop(32),\n",
        "    # 转换至Tensor\n",
        "    transforms.ToTensor(),\n",
        "    ])"
      ],
      "metadata": {
        "id": "TxoYrdwKits0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_CIFAR = True\n",
        "DOWNLOAD_CIFAR = False\n",
        "# 从data继承读取数据集的类\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# 训练数据集\n",
        "train_data = torchvision.datasets.CIFAR10(\n",
        "    root='/Data/My Drive/dataset',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=DOWNLOAD_CIFAR,\n",
        ")\n",
        "\n",
        "# 测试数据集\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='/Data/My Drive/dataset',\n",
        "    train=False,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "\n",
        "# 生成数据加载器\n",
        "# 训练数据加载器\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "# 测试数据加载器\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ],
      "metadata": {
        "id": "c0IVXuIfcbtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看数据,取一组batch\n",
        "data_iter = iter(test_loader)\n",
        "\n",
        "images, labels = next(data_iter)\n",
        "# 取batch中的一张图像\n",
        "idx = 5\n",
        "image = images[idx].numpy()\n",
        "image = np.transpose(image, (1,2,0))\n",
        "plt.imshow(image)\n",
        "print(classes[labels[idx].numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "OqUP_tXQjYk_",
        "outputId": "9bfbd629-bd11-42b6-e0f8-d530a3d356fc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 搭建卷积神经网络模型\n",
        "# 三个卷积层\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # 卷积层计算\n",
        "            nn.Conv2d(3, 8, kernel_size=5, stride=1, padding=2),\n",
        "            #  批归一化\n",
        "            nn.BatchNorm2d(8),\n",
        "            #ReLU激活函数\n",
        "            nn.ReLU(),\n",
        "            # 池化层：最大池化\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))# 搭建卷积神经网络模型\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))# 搭建卷积神经网络模型\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            #nn.Dropout(),\n",
        "            nn.Linear(4*4*32, 120),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, num_classes),\n",
        "        )\n",
        "\n",
        "    # 定义前向传播顺序\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5aS7E2BBkpLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化一个模型\n",
        "model = ConvNet(num_classes)"
      ],
      "metadata": {
        "id": "VK07kYOHk2Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "2qUHkTdhksvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置cuda-gpu\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTuV8mucco2z",
        "outputId": "fb50f57f-87a8-458d-f7ee-1297da4486b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Thu Jul  6 09:10:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 开始训练\n",
        "model = model.cuda()\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        # 前向传播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 反向传播和优化\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbRva835lY5b",
        "outputId": "68542628-3ebe-4355-d4a3-dcc02a9b7620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/5000], Loss: 1.9389\n",
            "Epoch [1/10], Step [200/5000], Loss: 2.1814\n",
            "Epoch [1/10], Step [300/5000], Loss: 1.4613\n",
            "Epoch [1/10], Step [400/5000], Loss: 2.0760\n",
            "Epoch [1/10], Step [500/5000], Loss: 1.5552\n",
            "Epoch [1/10], Step [600/5000], Loss: 2.2862\n",
            "Epoch [1/10], Step [700/5000], Loss: 1.8130\n",
            "Epoch [1/10], Step [800/5000], Loss: 1.4952\n",
            "Epoch [1/10], Step [900/5000], Loss: 2.1959\n",
            "Epoch [1/10], Step [1000/5000], Loss: 1.7233\n",
            "Epoch [1/10], Step [1100/5000], Loss: 1.8182\n",
            "Epoch [1/10], Step [1200/5000], Loss: 2.2403\n",
            "Epoch [1/10], Step [1300/5000], Loss: 1.3424\n",
            "Epoch [1/10], Step [1400/5000], Loss: 1.5374\n",
            "Epoch [1/10], Step [1500/5000], Loss: 2.1392\n",
            "Epoch [1/10], Step [1600/5000], Loss: 1.9356\n",
            "Epoch [1/10], Step [1700/5000], Loss: 1.6400\n",
            "Epoch [1/10], Step [1800/5000], Loss: 1.6147\n",
            "Epoch [1/10], Step [1900/5000], Loss: 1.7813\n",
            "Epoch [1/10], Step [2000/5000], Loss: 1.4669\n",
            "Epoch [1/10], Step [2100/5000], Loss: 1.3718\n",
            "Epoch [1/10], Step [2200/5000], Loss: 1.6863\n",
            "Epoch [1/10], Step [2300/5000], Loss: 2.5451\n",
            "Epoch [1/10], Step [2400/5000], Loss: 1.0726\n",
            "Epoch [1/10], Step [2500/5000], Loss: 1.6322\n",
            "Epoch [1/10], Step [2600/5000], Loss: 1.0164\n",
            "Epoch [1/10], Step [2700/5000], Loss: 2.0861\n",
            "Epoch [1/10], Step [2800/5000], Loss: 1.5005\n",
            "Epoch [1/10], Step [2900/5000], Loss: 1.2623\n",
            "Epoch [1/10], Step [3000/5000], Loss: 1.5559\n",
            "Epoch [1/10], Step [3100/5000], Loss: 1.6992\n",
            "Epoch [1/10], Step [3200/5000], Loss: 1.4014\n",
            "Epoch [1/10], Step [3300/5000], Loss: 2.0878\n",
            "Epoch [1/10], Step [3400/5000], Loss: 1.4196\n",
            "Epoch [1/10], Step [3500/5000], Loss: 1.0862\n",
            "Epoch [1/10], Step [3600/5000], Loss: 1.6137\n",
            "Epoch [1/10], Step [3700/5000], Loss: 2.3090\n",
            "Epoch [1/10], Step [3800/5000], Loss: 1.9412\n",
            "Epoch [1/10], Step [3900/5000], Loss: 1.4075\n",
            "Epoch [1/10], Step [4000/5000], Loss: 1.9289\n",
            "Epoch [1/10], Step [4100/5000], Loss: 1.4204\n",
            "Epoch [1/10], Step [4200/5000], Loss: 1.1194\n",
            "Epoch [1/10], Step [4300/5000], Loss: 0.7642\n",
            "Epoch [1/10], Step [4400/5000], Loss: 1.1760\n",
            "Epoch [1/10], Step [4500/5000], Loss: 1.0289\n",
            "Epoch [1/10], Step [4600/5000], Loss: 0.9799\n",
            "Epoch [1/10], Step [4700/5000], Loss: 1.5495\n",
            "Epoch [1/10], Step [4800/5000], Loss: 0.9206\n",
            "Epoch [1/10], Step [4900/5000], Loss: 1.2408\n",
            "Epoch [1/10], Step [5000/5000], Loss: 1.5004\n",
            "Epoch [2/10], Step [100/5000], Loss: 1.3660\n",
            "Epoch [2/10], Step [200/5000], Loss: 1.2058\n",
            "Epoch [2/10], Step [300/5000], Loss: 1.5721\n",
            "Epoch [2/10], Step [400/5000], Loss: 1.7142\n",
            "Epoch [2/10], Step [500/5000], Loss: 2.2276\n",
            "Epoch [2/10], Step [600/5000], Loss: 1.1763\n",
            "Epoch [2/10], Step [700/5000], Loss: 1.5520\n",
            "Epoch [2/10], Step [800/5000], Loss: 1.4205\n",
            "Epoch [2/10], Step [900/5000], Loss: 1.4107\n",
            "Epoch [2/10], Step [1000/5000], Loss: 1.3344\n",
            "Epoch [2/10], Step [1100/5000], Loss: 1.5588\n",
            "Epoch [2/10], Step [1200/5000], Loss: 2.0591\n",
            "Epoch [2/10], Step [1300/5000], Loss: 1.4905\n",
            "Epoch [2/10], Step [1400/5000], Loss: 1.0616\n",
            "Epoch [2/10], Step [1500/5000], Loss: 1.2644\n",
            "Epoch [2/10], Step [1600/5000], Loss: 1.0923\n",
            "Epoch [2/10], Step [1700/5000], Loss: 1.1473\n",
            "Epoch [2/10], Step [1800/5000], Loss: 1.6786\n",
            "Epoch [2/10], Step [1900/5000], Loss: 1.9932\n",
            "Epoch [2/10], Step [2000/5000], Loss: 1.2722\n",
            "Epoch [2/10], Step [2100/5000], Loss: 1.4091\n",
            "Epoch [2/10], Step [2200/5000], Loss: 0.7702\n",
            "Epoch [2/10], Step [2300/5000], Loss: 0.8885\n",
            "Epoch [2/10], Step [2400/5000], Loss: 0.8074\n",
            "Epoch [2/10], Step [2500/5000], Loss: 1.6077\n",
            "Epoch [2/10], Step [2600/5000], Loss: 1.2531\n",
            "Epoch [2/10], Step [2700/5000], Loss: 1.3464\n",
            "Epoch [2/10], Step [2800/5000], Loss: 2.4229\n",
            "Epoch [2/10], Step [2900/5000], Loss: 1.3010\n",
            "Epoch [2/10], Step [3000/5000], Loss: 0.8414\n",
            "Epoch [2/10], Step [3100/5000], Loss: 1.0930\n",
            "Epoch [2/10], Step [3200/5000], Loss: 1.5048\n",
            "Epoch [2/10], Step [3300/5000], Loss: 1.6933\n",
            "Epoch [2/10], Step [3400/5000], Loss: 1.5649\n",
            "Epoch [2/10], Step [3500/5000], Loss: 1.0509\n",
            "Epoch [2/10], Step [3600/5000], Loss: 1.3163\n",
            "Epoch [2/10], Step [3700/5000], Loss: 1.3091\n",
            "Epoch [2/10], Step [3800/5000], Loss: 1.7102\n",
            "Epoch [2/10], Step [3900/5000], Loss: 1.2013\n",
            "Epoch [2/10], Step [4000/5000], Loss: 1.1707\n",
            "Epoch [2/10], Step [4100/5000], Loss: 1.1912\n",
            "Epoch [2/10], Step [4200/5000], Loss: 1.0756\n",
            "Epoch [2/10], Step [4300/5000], Loss: 1.0517\n",
            "Epoch [2/10], Step [4400/5000], Loss: 1.2140\n",
            "Epoch [2/10], Step [4500/5000], Loss: 1.0991\n",
            "Epoch [2/10], Step [4600/5000], Loss: 1.0562\n",
            "Epoch [2/10], Step [4700/5000], Loss: 1.6164\n",
            "Epoch [2/10], Step [4800/5000], Loss: 1.5998\n",
            "Epoch [2/10], Step [4900/5000], Loss: 0.6602\n",
            "Epoch [2/10], Step [5000/5000], Loss: 1.2749\n",
            "Epoch [3/10], Step [100/5000], Loss: 1.1121\n",
            "Epoch [3/10], Step [200/5000], Loss: 0.9255\n",
            "Epoch [3/10], Step [300/5000], Loss: 1.0119\n",
            "Epoch [3/10], Step [400/5000], Loss: 1.1760\n",
            "Epoch [3/10], Step [500/5000], Loss: 1.2459\n",
            "Epoch [3/10], Step [600/5000], Loss: 0.8504\n",
            "Epoch [3/10], Step [700/5000], Loss: 0.6745\n",
            "Epoch [3/10], Step [800/5000], Loss: 1.1520\n",
            "Epoch [3/10], Step [900/5000], Loss: 1.2500\n",
            "Epoch [3/10], Step [1000/5000], Loss: 1.4284\n",
            "Epoch [3/10], Step [1100/5000], Loss: 0.8993\n",
            "Epoch [3/10], Step [1200/5000], Loss: 1.1959\n",
            "Epoch [3/10], Step [1300/5000], Loss: 0.4749\n",
            "Epoch [3/10], Step [1400/5000], Loss: 0.7349\n",
            "Epoch [3/10], Step [1500/5000], Loss: 1.0631\n",
            "Epoch [3/10], Step [1600/5000], Loss: 0.6807\n",
            "Epoch [3/10], Step [1700/5000], Loss: 1.0213\n",
            "Epoch [3/10], Step [1800/5000], Loss: 0.8814\n",
            "Epoch [3/10], Step [1900/5000], Loss: 1.5431\n",
            "Epoch [3/10], Step [2000/5000], Loss: 1.1397\n",
            "Epoch [3/10], Step [2100/5000], Loss: 1.3405\n",
            "Epoch [3/10], Step [2200/5000], Loss: 1.7826\n",
            "Epoch [3/10], Step [2300/5000], Loss: 0.7213\n",
            "Epoch [3/10], Step [2400/5000], Loss: 1.7371\n",
            "Epoch [3/10], Step [2500/5000], Loss: 0.9150\n",
            "Epoch [3/10], Step [2600/5000], Loss: 1.1237\n",
            "Epoch [3/10], Step [2700/5000], Loss: 1.2177\n",
            "Epoch [3/10], Step [2800/5000], Loss: 1.1951\n",
            "Epoch [3/10], Step [2900/5000], Loss: 1.2847\n",
            "Epoch [3/10], Step [3000/5000], Loss: 1.0196\n",
            "Epoch [3/10], Step [3100/5000], Loss: 1.0949\n",
            "Epoch [3/10], Step [3200/5000], Loss: 1.4648\n",
            "Epoch [3/10], Step [3300/5000], Loss: 1.9379\n",
            "Epoch [3/10], Step [3400/5000], Loss: 1.1735\n",
            "Epoch [3/10], Step [3500/5000], Loss: 0.9185\n",
            "Epoch [3/10], Step [3600/5000], Loss: 1.0060\n",
            "Epoch [3/10], Step [3700/5000], Loss: 1.1838\n",
            "Epoch [3/10], Step [3800/5000], Loss: 1.0821\n",
            "Epoch [3/10], Step [3900/5000], Loss: 0.9026\n",
            "Epoch [3/10], Step [4000/5000], Loss: 1.0388\n",
            "Epoch [3/10], Step [4100/5000], Loss: 0.9420\n",
            "Epoch [3/10], Step [4200/5000], Loss: 1.7339\n",
            "Epoch [3/10], Step [4300/5000], Loss: 0.8168\n",
            "Epoch [3/10], Step [4400/5000], Loss: 0.8581\n",
            "Epoch [3/10], Step [4500/5000], Loss: 1.0024\n",
            "Epoch [3/10], Step [4600/5000], Loss: 1.4934\n",
            "Epoch [3/10], Step [4700/5000], Loss: 1.3982\n",
            "Epoch [3/10], Step [4800/5000], Loss: 1.2844\n",
            "Epoch [3/10], Step [4900/5000], Loss: 1.1723\n",
            "Epoch [3/10], Step [5000/5000], Loss: 1.3734\n",
            "Epoch [4/10], Step [100/5000], Loss: 1.1390\n",
            "Epoch [4/10], Step [200/5000], Loss: 0.8963\n",
            "Epoch [4/10], Step [300/5000], Loss: 1.4171\n",
            "Epoch [4/10], Step [400/5000], Loss: 0.9722\n",
            "Epoch [4/10], Step [500/5000], Loss: 0.6069\n",
            "Epoch [4/10], Step [600/5000], Loss: 0.7846\n",
            "Epoch [4/10], Step [700/5000], Loss: 1.0086\n",
            "Epoch [4/10], Step [800/5000], Loss: 1.2449\n",
            "Epoch [4/10], Step [900/5000], Loss: 1.5609\n",
            "Epoch [4/10], Step [1000/5000], Loss: 1.2532\n",
            "Epoch [4/10], Step [1100/5000], Loss: 0.7860\n",
            "Epoch [4/10], Step [1200/5000], Loss: 0.9810\n",
            "Epoch [4/10], Step [1300/5000], Loss: 0.8470\n",
            "Epoch [4/10], Step [1400/5000], Loss: 0.9481\n",
            "Epoch [4/10], Step [1500/5000], Loss: 0.5787\n",
            "Epoch [4/10], Step [1600/5000], Loss: 1.1308\n",
            "Epoch [4/10], Step [1700/5000], Loss: 1.9435\n",
            "Epoch [4/10], Step [1800/5000], Loss: 1.3095\n",
            "Epoch [4/10], Step [1900/5000], Loss: 0.8991\n",
            "Epoch [4/10], Step [2000/5000], Loss: 1.8202\n",
            "Epoch [4/10], Step [2100/5000], Loss: 1.8213\n",
            "Epoch [4/10], Step [2200/5000], Loss: 0.6989\n",
            "Epoch [4/10], Step [2300/5000], Loss: 0.9433\n",
            "Epoch [4/10], Step [2400/5000], Loss: 0.6524\n",
            "Epoch [4/10], Step [2500/5000], Loss: 1.0198\n",
            "Epoch [4/10], Step [2600/5000], Loss: 1.3301\n",
            "Epoch [4/10], Step [2700/5000], Loss: 1.0778\n",
            "Epoch [4/10], Step [2800/5000], Loss: 1.5426\n",
            "Epoch [4/10], Step [2900/5000], Loss: 0.8629\n",
            "Epoch [4/10], Step [3000/5000], Loss: 1.7018\n",
            "Epoch [4/10], Step [3100/5000], Loss: 1.3134\n",
            "Epoch [4/10], Step [3200/5000], Loss: 0.9540\n",
            "Epoch [4/10], Step [3300/5000], Loss: 1.3258\n",
            "Epoch [4/10], Step [3400/5000], Loss: 1.3954\n",
            "Epoch [4/10], Step [3500/5000], Loss: 1.3119\n",
            "Epoch [4/10], Step [3600/5000], Loss: 1.1108\n",
            "Epoch [4/10], Step [3700/5000], Loss: 0.6670\n",
            "Epoch [4/10], Step [3800/5000], Loss: 1.0354\n",
            "Epoch [4/10], Step [3900/5000], Loss: 0.7736\n",
            "Epoch [4/10], Step [4000/5000], Loss: 0.4894\n",
            "Epoch [4/10], Step [4100/5000], Loss: 1.5279\n",
            "Epoch [4/10], Step [4200/5000], Loss: 1.0225\n",
            "Epoch [4/10], Step [4300/5000], Loss: 0.6324\n",
            "Epoch [4/10], Step [4400/5000], Loss: 0.5676\n",
            "Epoch [4/10], Step [4500/5000], Loss: 0.7107\n",
            "Epoch [4/10], Step [4600/5000], Loss: 1.2288\n",
            "Epoch [4/10], Step [4700/5000], Loss: 0.7699\n",
            "Epoch [4/10], Step [4800/5000], Loss: 0.9698\n",
            "Epoch [4/10], Step [4900/5000], Loss: 0.9165\n",
            "Epoch [4/10], Step [5000/5000], Loss: 1.1724\n",
            "Epoch [5/10], Step [100/5000], Loss: 1.2828\n",
            "Epoch [5/10], Step [200/5000], Loss: 1.2348\n",
            "Epoch [5/10], Step [300/5000], Loss: 1.5145\n",
            "Epoch [5/10], Step [400/5000], Loss: 1.4521\n",
            "Epoch [5/10], Step [500/5000], Loss: 0.6453\n",
            "Epoch [5/10], Step [600/5000], Loss: 1.0787\n",
            "Epoch [5/10], Step [700/5000], Loss: 0.5493\n",
            "Epoch [5/10], Step [800/5000], Loss: 1.0186\n",
            "Epoch [5/10], Step [900/5000], Loss: 1.2547\n",
            "Epoch [5/10], Step [1000/5000], Loss: 0.8511\n",
            "Epoch [5/10], Step [1100/5000], Loss: 1.4868\n",
            "Epoch [5/10], Step [1200/5000], Loss: 0.8454\n",
            "Epoch [5/10], Step [1300/5000], Loss: 1.4915\n",
            "Epoch [5/10], Step [1400/5000], Loss: 0.8875\n",
            "Epoch [5/10], Step [1500/5000], Loss: 1.1832\n",
            "Epoch [5/10], Step [1600/5000], Loss: 1.2908\n",
            "Epoch [5/10], Step [1700/5000], Loss: 1.1314\n",
            "Epoch [5/10], Step [1800/5000], Loss: 0.9338\n",
            "Epoch [5/10], Step [1900/5000], Loss: 1.2201\n",
            "Epoch [5/10], Step [2000/5000], Loss: 1.0356\n",
            "Epoch [5/10], Step [2100/5000], Loss: 0.9997\n",
            "Epoch [5/10], Step [2200/5000], Loss: 1.2853\n",
            "Epoch [5/10], Step [2300/5000], Loss: 0.6432\n",
            "Epoch [5/10], Step [2400/5000], Loss: 1.1152\n",
            "Epoch [5/10], Step [2500/5000], Loss: 1.1629\n",
            "Epoch [5/10], Step [2600/5000], Loss: 0.4824\n",
            "Epoch [5/10], Step [2700/5000], Loss: 0.7936\n",
            "Epoch [5/10], Step [2800/5000], Loss: 0.9421\n",
            "Epoch [5/10], Step [2900/5000], Loss: 1.8582\n",
            "Epoch [5/10], Step [3000/5000], Loss: 1.1405\n",
            "Epoch [5/10], Step [3100/5000], Loss: 1.0776\n",
            "Epoch [5/10], Step [3200/5000], Loss: 0.9667\n",
            "Epoch [5/10], Step [3300/5000], Loss: 1.0813\n",
            "Epoch [5/10], Step [3400/5000], Loss: 1.7053\n",
            "Epoch [5/10], Step [3500/5000], Loss: 1.5183\n",
            "Epoch [5/10], Step [3600/5000], Loss: 0.9201\n",
            "Epoch [5/10], Step [3700/5000], Loss: 0.7760\n",
            "Epoch [5/10], Step [3800/5000], Loss: 0.8119\n",
            "Epoch [5/10], Step [3900/5000], Loss: 1.4618\n",
            "Epoch [5/10], Step [4000/5000], Loss: 1.1414\n",
            "Epoch [5/10], Step [4100/5000], Loss: 1.1638\n",
            "Epoch [5/10], Step [4200/5000], Loss: 1.4107\n",
            "Epoch [5/10], Step [4300/5000], Loss: 0.5289\n",
            "Epoch [5/10], Step [4400/5000], Loss: 1.0770\n",
            "Epoch [5/10], Step [4500/5000], Loss: 0.8468\n",
            "Epoch [5/10], Step [4600/5000], Loss: 0.8953\n",
            "Epoch [5/10], Step [4700/5000], Loss: 1.1986\n",
            "Epoch [5/10], Step [4800/5000], Loss: 0.6131\n",
            "Epoch [5/10], Step [4900/5000], Loss: 0.6457\n",
            "Epoch [5/10], Step [5000/5000], Loss: 0.8168\n",
            "Epoch [6/10], Step [100/5000], Loss: 1.6625\n",
            "Epoch [6/10], Step [200/5000], Loss: 0.6829\n",
            "Epoch [6/10], Step [300/5000], Loss: 0.5210\n",
            "Epoch [6/10], Step [400/5000], Loss: 1.4302\n",
            "Epoch [6/10], Step [500/5000], Loss: 1.3435\n",
            "Epoch [6/10], Step [600/5000], Loss: 0.9587\n",
            "Epoch [6/10], Step [700/5000], Loss: 1.0040\n",
            "Epoch [6/10], Step [800/5000], Loss: 1.0281\n",
            "Epoch [6/10], Step [900/5000], Loss: 0.9654\n",
            "Epoch [6/10], Step [1000/5000], Loss: 1.2919\n",
            "Epoch [6/10], Step [1100/5000], Loss: 0.7930\n",
            "Epoch [6/10], Step [1200/5000], Loss: 1.2697\n",
            "Epoch [6/10], Step [1300/5000], Loss: 1.6487\n",
            "Epoch [6/10], Step [1400/5000], Loss: 0.7288\n",
            "Epoch [6/10], Step [1500/5000], Loss: 1.0092\n",
            "Epoch [6/10], Step [1600/5000], Loss: 1.3563\n",
            "Epoch [6/10], Step [1700/5000], Loss: 1.0319\n",
            "Epoch [6/10], Step [1800/5000], Loss: 1.1986\n",
            "Epoch [6/10], Step [1900/5000], Loss: 1.0671\n",
            "Epoch [6/10], Step [2000/5000], Loss: 1.0848\n",
            "Epoch [6/10], Step [2100/5000], Loss: 1.0864\n",
            "Epoch [6/10], Step [2200/5000], Loss: 1.4755\n",
            "Epoch [6/10], Step [2300/5000], Loss: 1.2345\n",
            "Epoch [6/10], Step [2400/5000], Loss: 0.5207\n",
            "Epoch [6/10], Step [2500/5000], Loss: 0.5617\n",
            "Epoch [6/10], Step [2600/5000], Loss: 0.6450\n",
            "Epoch [6/10], Step [2700/5000], Loss: 0.4908\n",
            "Epoch [6/10], Step [2800/5000], Loss: 0.6430\n",
            "Epoch [6/10], Step [2900/5000], Loss: 1.0005\n",
            "Epoch [6/10], Step [3000/5000], Loss: 0.7208\n",
            "Epoch [6/10], Step [3100/5000], Loss: 0.9385\n",
            "Epoch [6/10], Step [3200/5000], Loss: 0.5917\n",
            "Epoch [6/10], Step [3300/5000], Loss: 1.7246\n",
            "Epoch [6/10], Step [3400/5000], Loss: 1.2547\n",
            "Epoch [6/10], Step [3500/5000], Loss: 1.3006\n",
            "Epoch [6/10], Step [3600/5000], Loss: 0.7270\n",
            "Epoch [6/10], Step [3700/5000], Loss: 0.9543\n",
            "Epoch [6/10], Step [3800/5000], Loss: 1.2670\n",
            "Epoch [6/10], Step [3900/5000], Loss: 0.7297\n",
            "Epoch [6/10], Step [4000/5000], Loss: 1.9937\n",
            "Epoch [6/10], Step [4100/5000], Loss: 1.4787\n",
            "Epoch [6/10], Step [4200/5000], Loss: 1.5397\n",
            "Epoch [6/10], Step [4300/5000], Loss: 0.8290\n",
            "Epoch [6/10], Step [4400/5000], Loss: 0.7069\n",
            "Epoch [6/10], Step [4500/5000], Loss: 0.5610\n",
            "Epoch [6/10], Step [4600/5000], Loss: 0.8399\n",
            "Epoch [6/10], Step [4700/5000], Loss: 1.2112\n",
            "Epoch [6/10], Step [4800/5000], Loss: 1.0505\n",
            "Epoch [6/10], Step [4900/5000], Loss: 1.6662\n",
            "Epoch [6/10], Step [5000/5000], Loss: 1.1529\n",
            "Epoch [7/10], Step [100/5000], Loss: 1.0944\n",
            "Epoch [7/10], Step [200/5000], Loss: 0.9298\n",
            "Epoch [7/10], Step [300/5000], Loss: 1.0611\n",
            "Epoch [7/10], Step [400/5000], Loss: 0.7260\n",
            "Epoch [7/10], Step [500/5000], Loss: 0.9874\n",
            "Epoch [7/10], Step [600/5000], Loss: 0.8913\n",
            "Epoch [7/10], Step [700/5000], Loss: 0.6971\n",
            "Epoch [7/10], Step [800/5000], Loss: 0.7554\n",
            "Epoch [7/10], Step [900/5000], Loss: 0.8182\n",
            "Epoch [7/10], Step [1000/5000], Loss: 0.8244\n",
            "Epoch [7/10], Step [1100/5000], Loss: 0.8340\n",
            "Epoch [7/10], Step [1200/5000], Loss: 0.6223\n",
            "Epoch [7/10], Step [1300/5000], Loss: 0.8795\n",
            "Epoch [7/10], Step [1400/5000], Loss: 0.4874\n",
            "Epoch [7/10], Step [1500/5000], Loss: 0.9676\n",
            "Epoch [7/10], Step [1600/5000], Loss: 0.5042\n",
            "Epoch [7/10], Step [1700/5000], Loss: 0.9717\n",
            "Epoch [7/10], Step [1800/5000], Loss: 0.3508\n",
            "Epoch [7/10], Step [1900/5000], Loss: 1.1810\n",
            "Epoch [7/10], Step [2000/5000], Loss: 0.9722\n",
            "Epoch [7/10], Step [2100/5000], Loss: 0.7535\n",
            "Epoch [7/10], Step [2200/5000], Loss: 0.7364\n",
            "Epoch [7/10], Step [2300/5000], Loss: 0.9260\n",
            "Epoch [7/10], Step [2400/5000], Loss: 0.8180\n",
            "Epoch [7/10], Step [2500/5000], Loss: 1.0535\n",
            "Epoch [7/10], Step [2600/5000], Loss: 1.1185\n",
            "Epoch [7/10], Step [2700/5000], Loss: 1.0509\n",
            "Epoch [7/10], Step [2800/5000], Loss: 1.3370\n",
            "Epoch [7/10], Step [2900/5000], Loss: 0.7559\n",
            "Epoch [7/10], Step [3000/5000], Loss: 0.8516\n",
            "Epoch [7/10], Step [3100/5000], Loss: 1.3466\n",
            "Epoch [7/10], Step [3200/5000], Loss: 1.3380\n",
            "Epoch [7/10], Step [3300/5000], Loss: 0.7042\n",
            "Epoch [7/10], Step [3400/5000], Loss: 1.2937\n",
            "Epoch [7/10], Step [3500/5000], Loss: 0.9811\n",
            "Epoch [7/10], Step [3600/5000], Loss: 1.0673\n",
            "Epoch [7/10], Step [3700/5000], Loss: 0.8445\n",
            "Epoch [7/10], Step [3800/5000], Loss: 1.1512\n",
            "Epoch [7/10], Step [3900/5000], Loss: 0.9342\n",
            "Epoch [7/10], Step [4000/5000], Loss: 0.5565\n",
            "Epoch [7/10], Step [4100/5000], Loss: 0.6363\n",
            "Epoch [7/10], Step [4200/5000], Loss: 1.8371\n",
            "Epoch [7/10], Step [4300/5000], Loss: 1.6319\n",
            "Epoch [7/10], Step [4400/5000], Loss: 1.0567\n",
            "Epoch [7/10], Step [4500/5000], Loss: 1.2472\n",
            "Epoch [7/10], Step [4600/5000], Loss: 1.6120\n",
            "Epoch [7/10], Step [4700/5000], Loss: 1.9906\n",
            "Epoch [7/10], Step [4800/5000], Loss: 1.3437\n",
            "Epoch [7/10], Step [4900/5000], Loss: 0.9106\n",
            "Epoch [7/10], Step [5000/5000], Loss: 1.2878\n",
            "Epoch [8/10], Step [100/5000], Loss: 1.2464\n",
            "Epoch [8/10], Step [200/5000], Loss: 0.8210\n",
            "Epoch [8/10], Step [300/5000], Loss: 1.4193\n",
            "Epoch [8/10], Step [400/5000], Loss: 0.7948\n",
            "Epoch [8/10], Step [500/5000], Loss: 0.8991\n",
            "Epoch [8/10], Step [600/5000], Loss: 1.0386\n",
            "Epoch [8/10], Step [700/5000], Loss: 1.3609\n",
            "Epoch [8/10], Step [800/5000], Loss: 0.7075\n",
            "Epoch [8/10], Step [900/5000], Loss: 0.9187\n",
            "Epoch [8/10], Step [1000/5000], Loss: 0.4233\n",
            "Epoch [8/10], Step [1100/5000], Loss: 0.4956\n",
            "Epoch [8/10], Step [1200/5000], Loss: 1.2575\n",
            "Epoch [8/10], Step [1300/5000], Loss: 1.2093\n",
            "Epoch [8/10], Step [1400/5000], Loss: 0.6053\n",
            "Epoch [8/10], Step [1500/5000], Loss: 1.5002\n",
            "Epoch [8/10], Step [1600/5000], Loss: 1.0889\n",
            "Epoch [8/10], Step [1700/5000], Loss: 0.9048\n",
            "Epoch [8/10], Step [1800/5000], Loss: 0.3655\n",
            "Epoch [8/10], Step [1900/5000], Loss: 0.8008\n",
            "Epoch [8/10], Step [2000/5000], Loss: 0.9968\n",
            "Epoch [8/10], Step [2100/5000], Loss: 1.0735\n",
            "Epoch [8/10], Step [2200/5000], Loss: 1.0441\n",
            "Epoch [8/10], Step [2300/5000], Loss: 0.8323\n",
            "Epoch [8/10], Step [2400/5000], Loss: 1.4456\n",
            "Epoch [8/10], Step [2500/5000], Loss: 0.8359\n",
            "Epoch [8/10], Step [2600/5000], Loss: 1.0597\n",
            "Epoch [8/10], Step [2700/5000], Loss: 1.2250\n",
            "Epoch [8/10], Step [2800/5000], Loss: 1.0760\n",
            "Epoch [8/10], Step [2900/5000], Loss: 0.6361\n",
            "Epoch [8/10], Step [3000/5000], Loss: 0.9793\n",
            "Epoch [8/10], Step [3100/5000], Loss: 0.5478\n",
            "Epoch [8/10], Step [3200/5000], Loss: 0.9967\n",
            "Epoch [8/10], Step [3300/5000], Loss: 1.0615\n",
            "Epoch [8/10], Step [3400/5000], Loss: 1.2160\n",
            "Epoch [8/10], Step [3500/5000], Loss: 0.7814\n",
            "Epoch [8/10], Step [3600/5000], Loss: 1.6945\n",
            "Epoch [8/10], Step [3700/5000], Loss: 0.4875\n",
            "Epoch [8/10], Step [3800/5000], Loss: 0.9677\n",
            "Epoch [8/10], Step [3900/5000], Loss: 0.8694\n",
            "Epoch [8/10], Step [4000/5000], Loss: 1.2444\n",
            "Epoch [8/10], Step [4100/5000], Loss: 1.2123\n",
            "Epoch [8/10], Step [4200/5000], Loss: 1.0242\n",
            "Epoch [8/10], Step [4300/5000], Loss: 0.6677\n",
            "Epoch [8/10], Step [4400/5000], Loss: 0.7647\n",
            "Epoch [8/10], Step [4500/5000], Loss: 1.2176\n",
            "Epoch [8/10], Step [4600/5000], Loss: 0.6424\n",
            "Epoch [8/10], Step [4700/5000], Loss: 0.8221\n",
            "Epoch [8/10], Step [4800/5000], Loss: 0.7952\n",
            "Epoch [8/10], Step [4900/5000], Loss: 0.5990\n",
            "Epoch [8/10], Step [5000/5000], Loss: 0.9221\n",
            "Epoch [9/10], Step [100/5000], Loss: 1.2352\n",
            "Epoch [9/10], Step [200/5000], Loss: 0.7092\n",
            "Epoch [9/10], Step [300/5000], Loss: 0.6272\n",
            "Epoch [9/10], Step [400/5000], Loss: 0.4188\n",
            "Epoch [9/10], Step [500/5000], Loss: 1.2736\n",
            "Epoch [9/10], Step [600/5000], Loss: 0.3229\n",
            "Epoch [9/10], Step [700/5000], Loss: 0.8442\n",
            "Epoch [9/10], Step [800/5000], Loss: 0.7632\n",
            "Epoch [9/10], Step [900/5000], Loss: 0.8731\n",
            "Epoch [9/10], Step [1000/5000], Loss: 0.8972\n",
            "Epoch [9/10], Step [1100/5000], Loss: 0.9702\n",
            "Epoch [9/10], Step [1200/5000], Loss: 1.1115\n",
            "Epoch [9/10], Step [1300/5000], Loss: 0.5952\n",
            "Epoch [9/10], Step [1400/5000], Loss: 1.2357\n",
            "Epoch [9/10], Step [1500/5000], Loss: 0.4279\n",
            "Epoch [9/10], Step [1600/5000], Loss: 1.1075\n",
            "Epoch [9/10], Step [1700/5000], Loss: 1.0461\n",
            "Epoch [9/10], Step [1800/5000], Loss: 1.2213\n",
            "Epoch [9/10], Step [1900/5000], Loss: 0.4168\n",
            "Epoch [9/10], Step [2000/5000], Loss: 1.2383\n",
            "Epoch [9/10], Step [2100/5000], Loss: 0.6038\n",
            "Epoch [9/10], Step [2200/5000], Loss: 0.2472\n",
            "Epoch [9/10], Step [2300/5000], Loss: 1.0550\n",
            "Epoch [9/10], Step [2400/5000], Loss: 0.8472\n",
            "Epoch [9/10], Step [2500/5000], Loss: 1.2058\n",
            "Epoch [9/10], Step [2600/5000], Loss: 0.6552\n",
            "Epoch [9/10], Step [2700/5000], Loss: 0.7698\n",
            "Epoch [9/10], Step [2800/5000], Loss: 1.2344\n",
            "Epoch [9/10], Step [2900/5000], Loss: 1.0281\n",
            "Epoch [9/10], Step [3000/5000], Loss: 0.9857\n",
            "Epoch [9/10], Step [3100/5000], Loss: 0.6539\n",
            "Epoch [9/10], Step [3200/5000], Loss: 0.8113\n",
            "Epoch [9/10], Step [3300/5000], Loss: 1.2015\n",
            "Epoch [9/10], Step [3400/5000], Loss: 0.6977\n",
            "Epoch [9/10], Step [3500/5000], Loss: 0.9831\n",
            "Epoch [9/10], Step [3600/5000], Loss: 0.2186\n",
            "Epoch [9/10], Step [3700/5000], Loss: 0.3660\n",
            "Epoch [9/10], Step [3800/5000], Loss: 1.3343\n",
            "Epoch [9/10], Step [3900/5000], Loss: 1.3822\n",
            "Epoch [9/10], Step [4000/5000], Loss: 0.7456\n",
            "Epoch [9/10], Step [4100/5000], Loss: 0.4690\n",
            "Epoch [9/10], Step [4200/5000], Loss: 1.8031\n",
            "Epoch [9/10], Step [4300/5000], Loss: 1.2784\n",
            "Epoch [9/10], Step [4400/5000], Loss: 0.8219\n",
            "Epoch [9/10], Step [4500/5000], Loss: 1.1107\n",
            "Epoch [9/10], Step [4600/5000], Loss: 0.4553\n",
            "Epoch [9/10], Step [4700/5000], Loss: 1.0274\n",
            "Epoch [9/10], Step [4800/5000], Loss: 1.2317\n",
            "Epoch [9/10], Step [4900/5000], Loss: 1.0327\n",
            "Epoch [9/10], Step [5000/5000], Loss: 1.3512\n",
            "Epoch [10/10], Step [100/5000], Loss: 0.8419\n",
            "Epoch [10/10], Step [200/5000], Loss: 0.4964\n",
            "Epoch [10/10], Step [300/5000], Loss: 1.1028\n",
            "Epoch [10/10], Step [400/5000], Loss: 1.2747\n",
            "Epoch [10/10], Step [500/5000], Loss: 1.3609\n",
            "Epoch [10/10], Step [600/5000], Loss: 0.8180\n",
            "Epoch [10/10], Step [700/5000], Loss: 1.2799\n",
            "Epoch [10/10], Step [800/5000], Loss: 0.8579\n",
            "Epoch [10/10], Step [900/5000], Loss: 0.4287\n",
            "Epoch [10/10], Step [1000/5000], Loss: 1.3141\n",
            "Epoch [10/10], Step [1100/5000], Loss: 0.8533\n",
            "Epoch [10/10], Step [1200/5000], Loss: 0.6972\n",
            "Epoch [10/10], Step [1300/5000], Loss: 1.6200\n",
            "Epoch [10/10], Step [1400/5000], Loss: 0.9606\n",
            "Epoch [10/10], Step [1500/5000], Loss: 0.8761\n",
            "Epoch [10/10], Step [1600/5000], Loss: 0.5073\n",
            "Epoch [10/10], Step [1700/5000], Loss: 0.7136\n",
            "Epoch [10/10], Step [1800/5000], Loss: 1.1613\n",
            "Epoch [10/10], Step [1900/5000], Loss: 0.8405\n",
            "Epoch [10/10], Step [2000/5000], Loss: 1.2774\n",
            "Epoch [10/10], Step [2100/5000], Loss: 0.9523\n",
            "Epoch [10/10], Step [2200/5000], Loss: 1.2908\n",
            "Epoch [10/10], Step [2300/5000], Loss: 1.0325\n",
            "Epoch [10/10], Step [2400/5000], Loss: 1.7580\n",
            "Epoch [10/10], Step [2500/5000], Loss: 1.7520\n",
            "Epoch [10/10], Step [2600/5000], Loss: 1.5722\n",
            "Epoch [10/10], Step [2700/5000], Loss: 0.9346\n",
            "Epoch [10/10], Step [2800/5000], Loss: 1.0109\n",
            "Epoch [10/10], Step [2900/5000], Loss: 1.0763\n",
            "Epoch [10/10], Step [3000/5000], Loss: 1.1395\n",
            "Epoch [10/10], Step [3100/5000], Loss: 0.7637\n",
            "Epoch [10/10], Step [3200/5000], Loss: 1.0021\n",
            "Epoch [10/10], Step [3300/5000], Loss: 0.8196\n",
            "Epoch [10/10], Step [3400/5000], Loss: 0.5426\n",
            "Epoch [10/10], Step [3500/5000], Loss: 1.7929\n",
            "Epoch [10/10], Step [3600/5000], Loss: 0.6996\n",
            "Epoch [10/10], Step [3700/5000], Loss: 0.7837\n",
            "Epoch [10/10], Step [3800/5000], Loss: 1.0974\n",
            "Epoch [10/10], Step [3900/5000], Loss: 1.2388\n",
            "Epoch [10/10], Step [4000/5000], Loss: 0.6995\n",
            "Epoch [10/10], Step [4100/5000], Loss: 1.2571\n",
            "Epoch [10/10], Step [4200/5000], Loss: 2.2942\n",
            "Epoch [10/10], Step [4300/5000], Loss: 0.4245\n",
            "Epoch [10/10], Step [4400/5000], Loss: 1.0658\n",
            "Epoch [10/10], Step [4500/5000], Loss: 0.9555\n",
            "Epoch [10/10], Step [4600/5000], Loss: 1.3585\n",
            "Epoch [10/10], Step [4700/5000], Loss: 0.8609\n",
            "Epoch [10/10], Step [4800/5000], Loss: 1.1989\n",
            "Epoch [10/10], Step [4900/5000], Loss: 0.9364\n",
            "Epoch [10/10], Step [5000/5000], Loss: 0.8608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置为评估模式\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqgepKuunHH2",
        "outputId": "ec3f9d49-189f-43c9-a73c-33e028b11123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=120, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 输出测试集精度\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU9l2rwJnRgT",
        "outputId": "3c43a6b8-78e1-403e-9a97-d0b25041a9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the test images: 67.73 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  保存模型\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "metadata": {
        "id": "f1oRlNU4ndmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 可视化数据查看\n",
        "# 查看数据,取一组batch\n",
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "# 取batch中的一张图像，显示图像和真实标签\n",
        "idx = 4\n",
        "image = images[idx].numpy()\n",
        "image = np.transpose(image, (1,2,0))\n",
        "plt.imshow(image)\n",
        "print('true:',classes[labels[idx].numpy()])\n",
        "# 转换为（B,C,H,W）大小\n",
        "imagebatch = image.reshape(-1,3,32,32)\n",
        "\n",
        "# 转换为torch tensor\n",
        "image_tensor = torch.from_numpy(imagebatch)\n",
        "image_tensor = image_tensor.cuda()\n",
        "# 调用模型进行评估\n",
        "model.eval()\n",
        "output = model(image_tensor)\n",
        "precise, predicted = torch.max(output.data, 1)\n",
        "pre = predicted.cpu().numpy()\n",
        "pci = precise.cpu().numpy()\n",
        "print(pre) # 查看预测结果ID\n",
        "print('result:',classes[pre[0]])\n",
        "#print(pci[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "OLPAo19Dn2kL",
        "outputId": "3d35e21b-16dc-46d1-9980-ed63f8170f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true: frog\n",
            "[8]\n",
            "result: ship\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}